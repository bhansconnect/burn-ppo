# PPO configuration for Liar's Dice

env = "liars_dice"
num_envs = 128
num_steps = 64
reward_shaping_coef = 0.05

learning_rate = 0.001
gamma = 0.99
gae_lambda = 0.95
clip_epsilon = 0.1
entropy_coef = 0.05
value_coef = 1.0
max_grad_norm = 0.5
target_kl = 0.02

total_steps = 30_000_000
num_epochs = 6

hidden_size = 512
num_hidden = 3
activation = "relu"

checkpoint_freq = 100_000
log_freq = 10_000
