# PPO configuration for CartPole

env = "cartpole"
num_envs = 32
num_steps = 128

learning_rate = 0.001
gamma = 0.99
gae_lambda = 0.95
clip_epsilon = 0.2
entropy_coef = 0.01
value_coef = 0.5
max_grad_norm = 0.5
normalize_obs = true

total_steps = 1_000_000
num_epochs = 4

hidden_size = 64
num_hidden = 2
activation = "relu"

checkpoint_freq = 10_000
log_freq = 1_000
